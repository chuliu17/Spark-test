{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# AutoGluon Tabular with SageMaker\n",
    "\n",
    "[AutoGluon](https://github.com/awslabs/autogluon) automates machine learning tasks enabling you to easily achieve strong predictive performance in your applications. With just a few lines of code, you can train and deploy high-accuracy deep learning models on tabular, image, and text data.\n",
    "This notebook shows how to use AutoGluon-Tabular with Amazon SageMaker by creating custom containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "If using a SageMaker hosted notebook, select kernel `conda_mxnet_p36`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='./setup.sh', returncode=126)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Make sure docker compose is set up properly for local mode\n",
    "subprocess.run(\"./setup.sh\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='apt install unzip', returncode=127)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Studio\n",
    "subprocess.run(\"apt-get update -y\", shell=True)\n",
    "subprocess.run(\"apt install unzip\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import sagemaker\n",
    "from time import sleep\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role, local, Model, utils, s3\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import StringDeserializer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# Print settings\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "\n",
    "# Account/s3 setup\n",
    "session = sagemaker.Session()\n",
    "local_session = local.LocalSession()\n",
    "bucket = session.default_bucket()\n",
    "prefix = \"sagemaker/autogluon-tabular\"\n",
    "region = session.boto_region_name\n",
    "role = get_execution_role()\n",
    "client = session.boto_session.client(\n",
    "    \"sts\", region_name=region, endpoint_url=utils.sts_regional_endpoint(region)\n",
    ")\n",
    "account = client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "registry_uri_training = sagemaker.image_uris.retrieve(\n",
    "    \"mxnet\",\n",
    "    region,\n",
    "    version=\"1.7.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    image_scope=\"training\",\n",
    ")\n",
    "registry_uri_inference = sagemaker.image_uris.retrieve(\n",
    "    \"mxnet\",\n",
    "    region,\n",
    "    version=\"1.7.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    image_scope=\"inference\",\n",
    ")\n",
    "ecr_uri_prefix = account + \".\" + \".\".join(registry_uri_training.split(\"/\")[0].split(\".\")[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Build docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Build the training/inference image and push to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "training_algorithm_name = \"autogluon-sagemaker-training\"\n",
    "inference_algorithm_name = \"autogluon-sagemaker-inference\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you may want to remove existing docker images to make a room to build autogluon containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(\"docker system prune -af\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subprocess.run(\n",
    "    f\"/bin/bash ./container-training/build_push_training.sh {account} {region} {training_algorithm_name} {ecr_uri_prefix} {registry_uri_training.split('/')[0].split('.')[0]} {registry_uri_training}\",\n",
    "    shell=True,\n",
    ")\n",
    "subprocess.run(\"docker system prune -af\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(\n",
    "    f\"/bin/bash ./container-inference/build_push_inference.sh {account} {region} {inference_algorithm_name} {ecr_uri_prefix} {registry_uri_training.split('/')[0].split('.')[0]} {registry_uri_inference}\",\n",
    "    shell=True,\n",
    ")\n",
    "subprocess.run(\"docker system prune -af\", shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way of building docker images using sm-docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new Amazon SageMaker Studio Image Build convenience package allows data scientists and developers to easily build custom container images from your Studio notebooks via a new CLI. \n",
    "Newly built Docker images are tagged and pushed to Amazon ECR. \n",
    "\n",
    "To use the CLI, you need to ensure the Amazon SageMaker execution role used by your Studio notebook environment (or another AWS Identity and Access Management (IAM) role, if you prefer) has the required permissions to interact with the resources used by the CLI, including access to CodeBuild and Amazon ECR. Your role should have a trust policy with CodeBuild. \n",
    "\n",
    "You also need to make sure the appropriate permissions are included in your role to run the build in CodeBuild, create a repository in Amazon ECR, and push images to that repository. \n",
    "\n",
    "See also: https://aws.amazon.com/blogs/machine-learning/using-the-amazon-sagemaker-studio-image-build-cli-to-build-container-images-from-your-studio-notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subprocess.run(\"pip install sagemaker-studio-image-build\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "training_repo_name = training_algorithm_name + ':latest'\n",
    "training_repo_name  \n",
    "\n",
    "!sm-docker build . --repository {training_repo_name} \\\n",
    "--file ./container-training/Dockerfile.training --build-arg REGISTRY_URI={registry_uri_training}\n",
    "\n",
    "inference_repo_name = inference_algorithm_name + ':latest'\n",
    "inference_repo_name  \n",
    "\n",
    "!sm-docker build . --repository {inference_repo_name} \\\n",
    "--file ./container-inference/Dockerfile.inference --build-arg REGISTRY_URI={registry_uri_inference}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "In this example we'll use the direct-marketing dataset to build a binary classification model that predicts whether customers will accept or decline a marketing offer.  \n",
    "First we'll download the data and split it into train and test sets. AutoGluon does not require a separate validation set (it uses bagged k-fold cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Download and unzip the data\n",
    "# subprocess.run(\n",
    "#     f\"aws s3 cp --region {region} s3://sagemaker-sample-data-{region}/autopilot/direct_marketing/bank-additional.zip .\",\n",
    "#     shell=True,\n",
    "# )\n",
    "# subprocess.run(\"unzip -qq -o bank-additional.zip\", shell=True)\n",
    "# subprocess.run(\"rm bank-additional.zip\", shell=True)\n",
    "\n",
    "local_data_path = \"./normalized.csv\"\n",
    "data = pd.read_csv(local_data_path)\n",
    "\n",
    "# Split train/test data\n",
    "train = data.sample(frac=0.8, random_state=42)\n",
    "test = data.drop(train.index)\n",
    "\n",
    "# Split test X/y\n",
    "label = \"genre\"\n",
    "y_test = test[label]\n",
    "X_test = test.drop(columns=[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>meanTempogram</th>\n",
       "      <th>stdTempogram</th>\n",
       "      <th>varTempogram</th>\n",
       "      <th>meanMFCC_1</th>\n",
       "      <th>stdMFCC_1</th>\n",
       "      <th>varMFCC_1</th>\n",
       "      <th>meanMFCC_2</th>\n",
       "      <th>stdMFCC_2</th>\n",
       "      <th>varMFCC_2</th>\n",
       "      <th>meanMFCC_3</th>\n",
       "      <th>stdMFCC_3</th>\n",
       "      <th>varMFCC_3</th>\n",
       "      <th>meanMFCC_4</th>\n",
       "      <th>stdMFCC_4</th>\n",
       "      <th>varMFCC_4</th>\n",
       "      <th>meanMFCC_5</th>\n",
       "      <th>stdMFCC_5</th>\n",
       "      <th>varMFCC_5</th>\n",
       "      <th>meanMFCC_6</th>\n",
       "      <th>stdMFCC_6</th>\n",
       "      <th>varMFCC_6</th>\n",
       "      <th>meanMFCC_7</th>\n",
       "      <th>stdMFCC_7</th>\n",
       "      <th>varMFCC_7</th>\n",
       "      <th>meanMFCC_8</th>\n",
       "      <th>stdMFCC_8</th>\n",
       "      <th>varMFCC_8</th>\n",
       "      <th>meanMFCC_9</th>\n",
       "      <th>stdMFCC_9</th>\n",
       "      <th>varMFCC_9</th>\n",
       "      <th>meanMFCC_10</th>\n",
       "      <th>stdMFCC_10</th>\n",
       "      <th>varMFCC_10</th>\n",
       "      <th>meanMFCC_11</th>\n",
       "      <th>stdMFCC_11</th>\n",
       "      <th>varMFCC_11</th>\n",
       "      <th>meanMFCC_12</th>\n",
       "      <th>stdMFCC_12</th>\n",
       "      <th>varMFCC_12</th>\n",
       "      <th>meanMFCC_13</th>\n",
       "      <th>stdMFCC_13</th>\n",
       "      <th>varMFCC_13</th>\n",
       "      <th>meanSpectralCentroid</th>\n",
       "      <th>stdSpectralCentroid</th>\n",
       "      <th>varSpectralCentroid</th>\n",
       "      <th>meanZeroCrossingRate</th>\n",
       "      <th>stdZeroCrossingRate</th>\n",
       "      <th>varZeroCrossingRate</th>\n",
       "      <th>meanChromaFrequencies</th>\n",
       "      <th>stdChromaFrequencies</th>\n",
       "      <th>varChromaFrequencies</th>\n",
       "      <th>meanSpectralRollOff</th>\n",
       "      <th>stdSpectralRollOff</th>\n",
       "      <th>varSpectralRollOff</th>\n",
       "      <th>meanSpectralBandwidth</th>\n",
       "      <th>stdSpectralBandwidth</th>\n",
       "      <th>varSpectralBandwidth</th>\n",
       "      <th>meanSpectralContrast</th>\n",
       "      <th>stdSpectralContrast</th>\n",
       "      <th>varSpectralContrast</th>\n",
       "      <th>meanSpectralFlatness</th>\n",
       "      <th>stdSpectralFlatness</th>\n",
       "      <th>varSpectralFlatness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>jazz</td>\n",
       "      <td>0.314589</td>\n",
       "      <td>0.254149</td>\n",
       "      <td>0.160138</td>\n",
       "      <td>0.608754</td>\n",
       "      <td>0.227671</td>\n",
       "      <td>0.077467</td>\n",
       "      <td>0.673336</td>\n",
       "      <td>0.259353</td>\n",
       "      <td>0.117975</td>\n",
       "      <td>0.559693</td>\n",
       "      <td>0.311830</td>\n",
       "      <td>0.139814</td>\n",
       "      <td>0.396798</td>\n",
       "      <td>0.340712</td>\n",
       "      <td>0.189345</td>\n",
       "      <td>0.584283</td>\n",
       "      <td>0.093185</td>\n",
       "      <td>0.032761</td>\n",
       "      <td>0.492108</td>\n",
       "      <td>0.194535</td>\n",
       "      <td>0.090470</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.096024</td>\n",
       "      <td>0.045933</td>\n",
       "      <td>0.355306</td>\n",
       "      <td>0.184465</td>\n",
       "      <td>0.092547</td>\n",
       "      <td>0.591702</td>\n",
       "      <td>0.174561</td>\n",
       "      <td>0.094353</td>\n",
       "      <td>0.358224</td>\n",
       "      <td>0.178639</td>\n",
       "      <td>0.087415</td>\n",
       "      <td>0.573260</td>\n",
       "      <td>0.095917</td>\n",
       "      <td>0.036938</td>\n",
       "      <td>0.437105</td>\n",
       "      <td>0.184182</td>\n",
       "      <td>0.094273</td>\n",
       "      <td>0.645136</td>\n",
       "      <td>0.283869</td>\n",
       "      <td>0.160472</td>\n",
       "      <td>0.221815</td>\n",
       "      <td>0.201252</td>\n",
       "      <td>0.056115</td>\n",
       "      <td>0.121430</td>\n",
       "      <td>0.087019</td>\n",
       "      <td>0.013563</td>\n",
       "      <td>0.229677</td>\n",
       "      <td>0.786529</td>\n",
       "      <td>0.749919</td>\n",
       "      <td>0.261275</td>\n",
       "      <td>0.380175</td>\n",
       "      <td>0.161852</td>\n",
       "      <td>0.378606</td>\n",
       "      <td>0.392879</td>\n",
       "      <td>0.207209</td>\n",
       "      <td>0.428007</td>\n",
       "      <td>0.177257</td>\n",
       "      <td>0.095407</td>\n",
       "      <td>0.010826</td>\n",
       "      <td>0.037977</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>metal</td>\n",
       "      <td>0.427414</td>\n",
       "      <td>0.367745</td>\n",
       "      <td>0.252432</td>\n",
       "      <td>0.791073</td>\n",
       "      <td>0.377333</td>\n",
       "      <td>0.176631</td>\n",
       "      <td>0.512640</td>\n",
       "      <td>0.142850</td>\n",
       "      <td>0.052731</td>\n",
       "      <td>0.500528</td>\n",
       "      <td>0.448799</td>\n",
       "      <td>0.250501</td>\n",
       "      <td>0.876582</td>\n",
       "      <td>0.247469</td>\n",
       "      <td>0.121977</td>\n",
       "      <td>0.573348</td>\n",
       "      <td>0.143785</td>\n",
       "      <td>0.055754</td>\n",
       "      <td>0.791817</td>\n",
       "      <td>0.139737</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.505028</td>\n",
       "      <td>0.206719</td>\n",
       "      <td>0.112089</td>\n",
       "      <td>0.667056</td>\n",
       "      <td>0.219528</td>\n",
       "      <td>0.114842</td>\n",
       "      <td>0.416856</td>\n",
       "      <td>0.182787</td>\n",
       "      <td>0.099636</td>\n",
       "      <td>0.673520</td>\n",
       "      <td>0.103689</td>\n",
       "      <td>0.045907</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>0.146669</td>\n",
       "      <td>0.061546</td>\n",
       "      <td>0.664920</td>\n",
       "      <td>0.153438</td>\n",
       "      <td>0.075713</td>\n",
       "      <td>0.468940</td>\n",
       "      <td>0.200424</td>\n",
       "      <td>0.103149</td>\n",
       "      <td>0.365758</td>\n",
       "      <td>0.296179</td>\n",
       "      <td>0.107968</td>\n",
       "      <td>0.255122</td>\n",
       "      <td>0.232964</td>\n",
       "      <td>0.067747</td>\n",
       "      <td>0.650728</td>\n",
       "      <td>0.514647</td>\n",
       "      <td>0.460181</td>\n",
       "      <td>0.445007</td>\n",
       "      <td>0.355386</td>\n",
       "      <td>0.143136</td>\n",
       "      <td>0.464974</td>\n",
       "      <td>0.209664</td>\n",
       "      <td>0.080678</td>\n",
       "      <td>0.535574</td>\n",
       "      <td>0.772773</td>\n",
       "      <td>0.674221</td>\n",
       "      <td>0.016682</td>\n",
       "      <td>0.042346</td>\n",
       "      <td>0.001818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>metal</td>\n",
       "      <td>0.395358</td>\n",
       "      <td>0.326509</td>\n",
       "      <td>0.217449</td>\n",
       "      <td>0.676874</td>\n",
       "      <td>0.186592</td>\n",
       "      <td>0.056942</td>\n",
       "      <td>0.356315</td>\n",
       "      <td>0.326525</td>\n",
       "      <td>0.164674</td>\n",
       "      <td>0.567737</td>\n",
       "      <td>0.338477</td>\n",
       "      <td>0.158992</td>\n",
       "      <td>0.510937</td>\n",
       "      <td>0.309423</td>\n",
       "      <td>0.165432</td>\n",
       "      <td>0.639610</td>\n",
       "      <td>0.276527</td>\n",
       "      <td>0.133473</td>\n",
       "      <td>0.552426</td>\n",
       "      <td>0.350408</td>\n",
       "      <td>0.199235</td>\n",
       "      <td>0.768443</td>\n",
       "      <td>0.307101</td>\n",
       "      <td>0.184308</td>\n",
       "      <td>0.474861</td>\n",
       "      <td>0.393186</td>\n",
       "      <td>0.247407</td>\n",
       "      <td>0.697506</td>\n",
       "      <td>0.235522</td>\n",
       "      <td>0.135296</td>\n",
       "      <td>0.576919</td>\n",
       "      <td>0.320299</td>\n",
       "      <td>0.184944</td>\n",
       "      <td>0.633876</td>\n",
       "      <td>0.141666</td>\n",
       "      <td>0.058964</td>\n",
       "      <td>0.605591</td>\n",
       "      <td>0.285196</td>\n",
       "      <td>0.163214</td>\n",
       "      <td>0.649899</td>\n",
       "      <td>0.238405</td>\n",
       "      <td>0.128192</td>\n",
       "      <td>0.619900</td>\n",
       "      <td>0.504570</td>\n",
       "      <td>0.278870</td>\n",
       "      <td>0.469943</td>\n",
       "      <td>0.395739</td>\n",
       "      <td>0.174642</td>\n",
       "      <td>0.599233</td>\n",
       "      <td>0.643202</td>\n",
       "      <td>0.593161</td>\n",
       "      <td>0.683152</td>\n",
       "      <td>0.598445</td>\n",
       "      <td>0.375799</td>\n",
       "      <td>0.712569</td>\n",
       "      <td>0.586955</td>\n",
       "      <td>0.398239</td>\n",
       "      <td>0.432068</td>\n",
       "      <td>0.425076</td>\n",
       "      <td>0.287915</td>\n",
       "      <td>0.105506</td>\n",
       "      <td>0.192903</td>\n",
       "      <td>0.037308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     genre  meanTempogram  stdTempogram  varTempogram  meanMFCC_1  stdMFCC_1  \\\n",
       "521   jazz       0.314589      0.254149      0.160138    0.608754   0.227671   \n",
       "737  metal       0.427414      0.367745      0.252432    0.791073   0.377333   \n",
       "740  metal       0.395358      0.326509      0.217449    0.676874   0.186592   \n",
       "\n",
       "     varMFCC_1  meanMFCC_2  stdMFCC_2  varMFCC_2  meanMFCC_3  stdMFCC_3  \\\n",
       "521   0.077467    0.673336   0.259353   0.117975    0.559693   0.311830   \n",
       "737   0.176631    0.512640   0.142850   0.052731    0.500528   0.448799   \n",
       "740   0.056942    0.356315   0.326525   0.164674    0.567737   0.338477   \n",
       "\n",
       "     varMFCC_3  meanMFCC_4  stdMFCC_4  varMFCC_4  meanMFCC_5  stdMFCC_5  \\\n",
       "521   0.139814    0.396798   0.340712   0.189345    0.584283   0.093185   \n",
       "737   0.250501    0.876582   0.247469   0.121977    0.573348   0.143785   \n",
       "740   0.158992    0.510937   0.309423   0.165432    0.639610   0.276527   \n",
       "\n",
       "     varMFCC_5  meanMFCC_6  stdMFCC_6  varMFCC_6  meanMFCC_7  stdMFCC_7  \\\n",
       "521   0.032761    0.492108   0.194535   0.090470    0.714469   0.096024   \n",
       "737   0.055754    0.791817   0.139737   0.059900    0.505028   0.206719   \n",
       "740   0.133473    0.552426   0.350408   0.199235    0.768443   0.307101   \n",
       "\n",
       "     varMFCC_7  meanMFCC_8  stdMFCC_8  varMFCC_8  meanMFCC_9  stdMFCC_9  \\\n",
       "521   0.045933    0.355306   0.184465   0.092547    0.591702   0.174561   \n",
       "737   0.112089    0.667056   0.219528   0.114842    0.416856   0.182787   \n",
       "740   0.184308    0.474861   0.393186   0.247407    0.697506   0.235522   \n",
       "\n",
       "     varMFCC_9  meanMFCC_10  stdMFCC_10  varMFCC_10  meanMFCC_11  stdMFCC_11  \\\n",
       "521   0.094353     0.358224    0.178639    0.087415     0.573260    0.095917   \n",
       "737   0.099636     0.673520    0.103689    0.045907     0.443367    0.146669   \n",
       "740   0.135296     0.576919    0.320299    0.184944     0.633876    0.141666   \n",
       "\n",
       "     varMFCC_11  meanMFCC_12  stdMFCC_12  varMFCC_12  meanMFCC_13  stdMFCC_13  \\\n",
       "521    0.036938     0.437105    0.184182    0.094273     0.645136    0.283869   \n",
       "737    0.061546     0.664920    0.153438    0.075713     0.468940    0.200424   \n",
       "740    0.058964     0.605591    0.285196    0.163214     0.649899    0.238405   \n",
       "\n",
       "     varMFCC_13  meanSpectralCentroid  stdSpectralCentroid  \\\n",
       "521    0.160472              0.221815             0.201252   \n",
       "737    0.103149              0.365758             0.296179   \n",
       "740    0.128192              0.619900             0.504570   \n",
       "\n",
       "     varSpectralCentroid  meanZeroCrossingRate  stdZeroCrossingRate  \\\n",
       "521             0.056115              0.121430             0.087019   \n",
       "737             0.107968              0.255122             0.232964   \n",
       "740             0.278870              0.469943             0.395739   \n",
       "\n",
       "     varZeroCrossingRate  meanChromaFrequencies  stdChromaFrequencies  \\\n",
       "521             0.013563               0.229677              0.786529   \n",
       "737             0.067747               0.650728              0.514647   \n",
       "740             0.174642               0.599233              0.643202   \n",
       "\n",
       "     varChromaFrequencies  meanSpectralRollOff  stdSpectralRollOff  \\\n",
       "521              0.749919             0.261275            0.380175   \n",
       "737              0.460181             0.445007            0.355386   \n",
       "740              0.593161             0.683152            0.598445   \n",
       "\n",
       "     varSpectralRollOff  meanSpectralBandwidth  stdSpectralBandwidth  \\\n",
       "521            0.161852               0.378606              0.392879   \n",
       "737            0.143136               0.464974              0.209664   \n",
       "740            0.375799               0.712569              0.586955   \n",
       "\n",
       "     varSpectralBandwidth  meanSpectralContrast  stdSpectralContrast  \\\n",
       "521              0.207209              0.428007             0.177257   \n",
       "737              0.080678              0.535574             0.772773   \n",
       "740              0.398239              0.432068             0.425076   \n",
       "\n",
       "     varSpectralContrast  meanSpectralFlatness  stdSpectralFlatness  \\\n",
       "521             0.095407              0.010826             0.037977   \n",
       "737             0.674221              0.016682             0.042346   \n",
       "740             0.287915              0.105506             0.192903   \n",
       "\n",
       "     varSpectralFlatness  \n",
       "521             0.001465  \n",
       "737             0.001818  \n",
       "740             0.037308  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(800, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>meanTempogram</th>\n",
       "      <th>stdTempogram</th>\n",
       "      <th>varTempogram</th>\n",
       "      <th>meanMFCC_1</th>\n",
       "      <th>stdMFCC_1</th>\n",
       "      <th>varMFCC_1</th>\n",
       "      <th>meanMFCC_2</th>\n",
       "      <th>stdMFCC_2</th>\n",
       "      <th>varMFCC_2</th>\n",
       "      <th>meanMFCC_3</th>\n",
       "      <th>stdMFCC_3</th>\n",
       "      <th>varMFCC_3</th>\n",
       "      <th>meanMFCC_4</th>\n",
       "      <th>stdMFCC_4</th>\n",
       "      <th>varMFCC_4</th>\n",
       "      <th>meanMFCC_5</th>\n",
       "      <th>stdMFCC_5</th>\n",
       "      <th>varMFCC_5</th>\n",
       "      <th>meanMFCC_6</th>\n",
       "      <th>stdMFCC_6</th>\n",
       "      <th>varMFCC_6</th>\n",
       "      <th>meanMFCC_7</th>\n",
       "      <th>stdMFCC_7</th>\n",
       "      <th>varMFCC_7</th>\n",
       "      <th>meanMFCC_8</th>\n",
       "      <th>stdMFCC_8</th>\n",
       "      <th>varMFCC_8</th>\n",
       "      <th>meanMFCC_9</th>\n",
       "      <th>stdMFCC_9</th>\n",
       "      <th>varMFCC_9</th>\n",
       "      <th>meanMFCC_10</th>\n",
       "      <th>stdMFCC_10</th>\n",
       "      <th>varMFCC_10</th>\n",
       "      <th>meanMFCC_11</th>\n",
       "      <th>stdMFCC_11</th>\n",
       "      <th>varMFCC_11</th>\n",
       "      <th>meanMFCC_12</th>\n",
       "      <th>stdMFCC_12</th>\n",
       "      <th>varMFCC_12</th>\n",
       "      <th>meanMFCC_13</th>\n",
       "      <th>stdMFCC_13</th>\n",
       "      <th>varMFCC_13</th>\n",
       "      <th>meanSpectralCentroid</th>\n",
       "      <th>stdSpectralCentroid</th>\n",
       "      <th>varSpectralCentroid</th>\n",
       "      <th>meanZeroCrossingRate</th>\n",
       "      <th>stdZeroCrossingRate</th>\n",
       "      <th>varZeroCrossingRate</th>\n",
       "      <th>meanChromaFrequencies</th>\n",
       "      <th>stdChromaFrequencies</th>\n",
       "      <th>varChromaFrequencies</th>\n",
       "      <th>meanSpectralRollOff</th>\n",
       "      <th>stdSpectralRollOff</th>\n",
       "      <th>varSpectralRollOff</th>\n",
       "      <th>meanSpectralBandwidth</th>\n",
       "      <th>stdSpectralBandwidth</th>\n",
       "      <th>varSpectralBandwidth</th>\n",
       "      <th>meanSpectralContrast</th>\n",
       "      <th>stdSpectralContrast</th>\n",
       "      <th>varSpectralContrast</th>\n",
       "      <th>meanSpectralFlatness</th>\n",
       "      <th>stdSpectralFlatness</th>\n",
       "      <th>varSpectralFlatness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reggae</td>\n",
       "      <td>0.251674</td>\n",
       "      <td>0.209781</td>\n",
       "      <td>0.127566</td>\n",
       "      <td>0.601865</td>\n",
       "      <td>0.411215</td>\n",
       "      <td>0.204393</td>\n",
       "      <td>0.617099</td>\n",
       "      <td>0.448078</td>\n",
       "      <td>0.266062</td>\n",
       "      <td>0.569494</td>\n",
       "      <td>0.381634</td>\n",
       "      <td>0.192466</td>\n",
       "      <td>0.598732</td>\n",
       "      <td>0.686925</td>\n",
       "      <td>0.542005</td>\n",
       "      <td>0.506231</td>\n",
       "      <td>0.455667</td>\n",
       "      <td>0.278308</td>\n",
       "      <td>0.732210</td>\n",
       "      <td>0.429512</td>\n",
       "      <td>0.266777</td>\n",
       "      <td>0.431441</td>\n",
       "      <td>0.676150</td>\n",
       "      <td>0.549790</td>\n",
       "      <td>0.491202</td>\n",
       "      <td>0.540061</td>\n",
       "      <td>0.388292</td>\n",
       "      <td>0.501946</td>\n",
       "      <td>0.713977</td>\n",
       "      <td>0.600301</td>\n",
       "      <td>0.697637</td>\n",
       "      <td>0.478588</td>\n",
       "      <td>0.323442</td>\n",
       "      <td>0.503482</td>\n",
       "      <td>0.286948</td>\n",
       "      <td>0.147788</td>\n",
       "      <td>0.555267</td>\n",
       "      <td>0.374413</td>\n",
       "      <td>0.234260</td>\n",
       "      <td>0.523616</td>\n",
       "      <td>0.472941</td>\n",
       "      <td>0.321634</td>\n",
       "      <td>0.290066</td>\n",
       "      <td>0.373626</td>\n",
       "      <td>0.162326</td>\n",
       "      <td>0.188749</td>\n",
       "      <td>0.241540</td>\n",
       "      <td>0.072156</td>\n",
       "      <td>0.400401</td>\n",
       "      <td>0.826589</td>\n",
       "      <td>0.795333</td>\n",
       "      <td>0.365662</td>\n",
       "      <td>0.541328</td>\n",
       "      <td>0.311284</td>\n",
       "      <td>0.407825</td>\n",
       "      <td>0.488073</td>\n",
       "      <td>0.293583</td>\n",
       "      <td>0.652288</td>\n",
       "      <td>0.562604</td>\n",
       "      <td>0.424493</td>\n",
       "      <td>0.009669</td>\n",
       "      <td>0.029061</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reggae</td>\n",
       "      <td>0.174107</td>\n",
       "      <td>0.163321</td>\n",
       "      <td>0.095551</td>\n",
       "      <td>0.752637</td>\n",
       "      <td>0.387832</td>\n",
       "      <td>0.185024</td>\n",
       "      <td>0.348909</td>\n",
       "      <td>0.635720</td>\n",
       "      <td>0.465276</td>\n",
       "      <td>0.597469</td>\n",
       "      <td>0.309881</td>\n",
       "      <td>0.138456</td>\n",
       "      <td>0.435811</td>\n",
       "      <td>0.509114</td>\n",
       "      <td>0.340705</td>\n",
       "      <td>0.672473</td>\n",
       "      <td>0.298856</td>\n",
       "      <td>0.149022</td>\n",
       "      <td>0.478061</td>\n",
       "      <td>0.528161</td>\n",
       "      <td>0.362653</td>\n",
       "      <td>0.632067</td>\n",
       "      <td>0.531175</td>\n",
       "      <td>0.387470</td>\n",
       "      <td>0.407135</td>\n",
       "      <td>0.526068</td>\n",
       "      <td>0.373733</td>\n",
       "      <td>0.643790</td>\n",
       "      <td>0.534757</td>\n",
       "      <td>0.396267</td>\n",
       "      <td>0.362759</td>\n",
       "      <td>0.391483</td>\n",
       "      <td>0.243373</td>\n",
       "      <td>0.681846</td>\n",
       "      <td>0.222939</td>\n",
       "      <td>0.105115</td>\n",
       "      <td>0.524689</td>\n",
       "      <td>0.286852</td>\n",
       "      <td>0.164446</td>\n",
       "      <td>0.781792</td>\n",
       "      <td>0.406446</td>\n",
       "      <td>0.260007</td>\n",
       "      <td>0.616986</td>\n",
       "      <td>0.766661</td>\n",
       "      <td>0.605143</td>\n",
       "      <td>0.416471</td>\n",
       "      <td>0.532536</td>\n",
       "      <td>0.302367</td>\n",
       "      <td>0.585827</td>\n",
       "      <td>0.662927</td>\n",
       "      <td>0.614202</td>\n",
       "      <td>0.645751</td>\n",
       "      <td>0.775026</td>\n",
       "      <td>0.613481</td>\n",
       "      <td>0.686209</td>\n",
       "      <td>0.584828</td>\n",
       "      <td>0.395828</td>\n",
       "      <td>0.315782</td>\n",
       "      <td>0.124489</td>\n",
       "      <td>0.063318</td>\n",
       "      <td>0.215885</td>\n",
       "      <td>0.452068</td>\n",
       "      <td>0.204520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>reggae</td>\n",
       "      <td>0.190306</td>\n",
       "      <td>0.162489</td>\n",
       "      <td>0.094997</td>\n",
       "      <td>0.818058</td>\n",
       "      <td>0.454506</td>\n",
       "      <td>0.242719</td>\n",
       "      <td>0.510609</td>\n",
       "      <td>0.609768</td>\n",
       "      <td>0.434636</td>\n",
       "      <td>0.484726</td>\n",
       "      <td>0.371896</td>\n",
       "      <td>0.184652</td>\n",
       "      <td>0.459279</td>\n",
       "      <td>0.481339</td>\n",
       "      <td>0.313109</td>\n",
       "      <td>0.752121</td>\n",
       "      <td>0.376308</td>\n",
       "      <td>0.208483</td>\n",
       "      <td>0.467799</td>\n",
       "      <td>0.605514</td>\n",
       "      <td>0.446873</td>\n",
       "      <td>0.773822</td>\n",
       "      <td>0.520902</td>\n",
       "      <td>0.376888</td>\n",
       "      <td>0.479969</td>\n",
       "      <td>0.372597</td>\n",
       "      <td>0.229764</td>\n",
       "      <td>0.620313</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.352543</td>\n",
       "      <td>0.513828</td>\n",
       "      <td>0.403445</td>\n",
       "      <td>0.253810</td>\n",
       "      <td>0.848489</td>\n",
       "      <td>0.381108</td>\n",
       "      <td>0.220689</td>\n",
       "      <td>0.612730</td>\n",
       "      <td>0.477182</td>\n",
       "      <td>0.327903</td>\n",
       "      <td>0.772189</td>\n",
       "      <td>0.301585</td>\n",
       "      <td>0.173730</td>\n",
       "      <td>0.390945</td>\n",
       "      <td>0.514024</td>\n",
       "      <td>0.288482</td>\n",
       "      <td>0.241661</td>\n",
       "      <td>0.281830</td>\n",
       "      <td>0.094690</td>\n",
       "      <td>0.414717</td>\n",
       "      <td>0.831555</td>\n",
       "      <td>0.801012</td>\n",
       "      <td>0.463441</td>\n",
       "      <td>0.685964</td>\n",
       "      <td>0.486380</td>\n",
       "      <td>0.523306</td>\n",
       "      <td>0.765962</td>\n",
       "      <td>0.626421</td>\n",
       "      <td>0.320781</td>\n",
       "      <td>0.135522</td>\n",
       "      <td>0.069769</td>\n",
       "      <td>0.061493</td>\n",
       "      <td>0.168321</td>\n",
       "      <td>0.028419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     genre  meanTempogram  stdTempogram  varTempogram  meanMFCC_1  stdMFCC_1  \\\n",
       "1   reggae       0.251674      0.209781      0.127566    0.601865   0.411215   \n",
       "4   reggae       0.174107      0.163321      0.095551    0.752637   0.387832   \n",
       "13  reggae       0.190306      0.162489      0.094997    0.818058   0.454506   \n",
       "\n",
       "    varMFCC_1  meanMFCC_2  stdMFCC_2  varMFCC_2  meanMFCC_3  stdMFCC_3  \\\n",
       "1    0.204393    0.617099   0.448078   0.266062    0.569494   0.381634   \n",
       "4    0.185024    0.348909   0.635720   0.465276    0.597469   0.309881   \n",
       "13   0.242719    0.510609   0.609768   0.434636    0.484726   0.371896   \n",
       "\n",
       "    varMFCC_3  meanMFCC_4  stdMFCC_4  varMFCC_4  meanMFCC_5  stdMFCC_5  \\\n",
       "1    0.192466    0.598732   0.686925   0.542005    0.506231   0.455667   \n",
       "4    0.138456    0.435811   0.509114   0.340705    0.672473   0.298856   \n",
       "13   0.184652    0.459279   0.481339   0.313109    0.752121   0.376308   \n",
       "\n",
       "    varMFCC_5  meanMFCC_6  stdMFCC_6  varMFCC_6  meanMFCC_7  stdMFCC_7  \\\n",
       "1    0.278308    0.732210   0.429512   0.266777    0.431441   0.676150   \n",
       "4    0.149022    0.478061   0.528161   0.362653    0.632067   0.531175   \n",
       "13   0.208483    0.467799   0.605514   0.446873    0.773822   0.520902   \n",
       "\n",
       "    varMFCC_7  meanMFCC_8  stdMFCC_8  varMFCC_8  meanMFCC_9  stdMFCC_9  \\\n",
       "1    0.549790    0.491202   0.540061   0.388292    0.501946   0.713977   \n",
       "4    0.387470    0.407135   0.526068   0.373733    0.643790   0.534757   \n",
       "13   0.376888    0.479969   0.372597   0.229764    0.620313   0.491667   \n",
       "\n",
       "    varMFCC_9  meanMFCC_10  stdMFCC_10  varMFCC_10  meanMFCC_11  stdMFCC_11  \\\n",
       "1    0.600301     0.697637    0.478588    0.323442     0.503482    0.286948   \n",
       "4    0.396267     0.362759    0.391483    0.243373     0.681846    0.222939   \n",
       "13   0.352543     0.513828    0.403445    0.253810     0.848489    0.381108   \n",
       "\n",
       "    varMFCC_11  meanMFCC_12  stdMFCC_12  varMFCC_12  meanMFCC_13  stdMFCC_13  \\\n",
       "1     0.147788     0.555267    0.374413    0.234260     0.523616    0.472941   \n",
       "4     0.105115     0.524689    0.286852    0.164446     0.781792    0.406446   \n",
       "13    0.220689     0.612730    0.477182    0.327903     0.772189    0.301585   \n",
       "\n",
       "    varMFCC_13  meanSpectralCentroid  stdSpectralCentroid  \\\n",
       "1     0.321634              0.290066             0.373626   \n",
       "4     0.260007              0.616986             0.766661   \n",
       "13    0.173730              0.390945             0.514024   \n",
       "\n",
       "    varSpectralCentroid  meanZeroCrossingRate  stdZeroCrossingRate  \\\n",
       "1              0.162326              0.188749             0.241540   \n",
       "4              0.605143              0.416471             0.532536   \n",
       "13             0.288482              0.241661             0.281830   \n",
       "\n",
       "    varZeroCrossingRate  meanChromaFrequencies  stdChromaFrequencies  \\\n",
       "1              0.072156               0.400401              0.826589   \n",
       "4              0.302367               0.585827              0.662927   \n",
       "13             0.094690               0.414717              0.831555   \n",
       "\n",
       "    varChromaFrequencies  meanSpectralRollOff  stdSpectralRollOff  \\\n",
       "1               0.795333             0.365662            0.541328   \n",
       "4               0.614202             0.645751            0.775026   \n",
       "13              0.801012             0.463441            0.685964   \n",
       "\n",
       "    varSpectralRollOff  meanSpectralBandwidth  stdSpectralBandwidth  \\\n",
       "1             0.311284               0.407825              0.488073   \n",
       "4             0.613481               0.686209              0.584828   \n",
       "13            0.486380               0.523306              0.765962   \n",
       "\n",
       "    varSpectralBandwidth  meanSpectralContrast  stdSpectralContrast  \\\n",
       "1               0.293583              0.652288             0.562604   \n",
       "4               0.395828              0.315782             0.124489   \n",
       "13              0.626421              0.320781             0.135522   \n",
       "\n",
       "    varSpectralContrast  meanSpectralFlatness  stdSpectralFlatness  \\\n",
       "1              0.424493              0.009669             0.029061   \n",
       "4              0.063318              0.215885             0.452068   \n",
       "13             0.069769              0.061493             0.168321   \n",
       "\n",
       "    varSpectralFlatness  \n",
       "1              0.000862  \n",
       "4              0.204520  \n",
       "13             0.028419  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(200, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanTempogram</th>\n",
       "      <th>stdTempogram</th>\n",
       "      <th>varTempogram</th>\n",
       "      <th>meanMFCC_1</th>\n",
       "      <th>stdMFCC_1</th>\n",
       "      <th>varMFCC_1</th>\n",
       "      <th>meanMFCC_2</th>\n",
       "      <th>stdMFCC_2</th>\n",
       "      <th>varMFCC_2</th>\n",
       "      <th>meanMFCC_3</th>\n",
       "      <th>stdMFCC_3</th>\n",
       "      <th>varMFCC_3</th>\n",
       "      <th>meanMFCC_4</th>\n",
       "      <th>stdMFCC_4</th>\n",
       "      <th>varMFCC_4</th>\n",
       "      <th>meanMFCC_5</th>\n",
       "      <th>stdMFCC_5</th>\n",
       "      <th>varMFCC_5</th>\n",
       "      <th>meanMFCC_6</th>\n",
       "      <th>stdMFCC_6</th>\n",
       "      <th>varMFCC_6</th>\n",
       "      <th>meanMFCC_7</th>\n",
       "      <th>stdMFCC_7</th>\n",
       "      <th>varMFCC_7</th>\n",
       "      <th>meanMFCC_8</th>\n",
       "      <th>stdMFCC_8</th>\n",
       "      <th>varMFCC_8</th>\n",
       "      <th>meanMFCC_9</th>\n",
       "      <th>stdMFCC_9</th>\n",
       "      <th>varMFCC_9</th>\n",
       "      <th>meanMFCC_10</th>\n",
       "      <th>stdMFCC_10</th>\n",
       "      <th>varMFCC_10</th>\n",
       "      <th>meanMFCC_11</th>\n",
       "      <th>stdMFCC_11</th>\n",
       "      <th>varMFCC_11</th>\n",
       "      <th>meanMFCC_12</th>\n",
       "      <th>stdMFCC_12</th>\n",
       "      <th>varMFCC_12</th>\n",
       "      <th>meanMFCC_13</th>\n",
       "      <th>stdMFCC_13</th>\n",
       "      <th>varMFCC_13</th>\n",
       "      <th>meanSpectralCentroid</th>\n",
       "      <th>stdSpectralCentroid</th>\n",
       "      <th>varSpectralCentroid</th>\n",
       "      <th>meanZeroCrossingRate</th>\n",
       "      <th>stdZeroCrossingRate</th>\n",
       "      <th>varZeroCrossingRate</th>\n",
       "      <th>meanChromaFrequencies</th>\n",
       "      <th>stdChromaFrequencies</th>\n",
       "      <th>varChromaFrequencies</th>\n",
       "      <th>meanSpectralRollOff</th>\n",
       "      <th>stdSpectralRollOff</th>\n",
       "      <th>varSpectralRollOff</th>\n",
       "      <th>meanSpectralBandwidth</th>\n",
       "      <th>stdSpectralBandwidth</th>\n",
       "      <th>varSpectralBandwidth</th>\n",
       "      <th>meanSpectralContrast</th>\n",
       "      <th>stdSpectralContrast</th>\n",
       "      <th>varSpectralContrast</th>\n",
       "      <th>meanSpectralFlatness</th>\n",
       "      <th>stdSpectralFlatness</th>\n",
       "      <th>varSpectralFlatness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.251674</td>\n",
       "      <td>0.209781</td>\n",
       "      <td>0.127566</td>\n",
       "      <td>0.601865</td>\n",
       "      <td>0.411215</td>\n",
       "      <td>0.204393</td>\n",
       "      <td>0.617099</td>\n",
       "      <td>0.448078</td>\n",
       "      <td>0.266062</td>\n",
       "      <td>0.569494</td>\n",
       "      <td>0.381634</td>\n",
       "      <td>0.192466</td>\n",
       "      <td>0.598732</td>\n",
       "      <td>0.686925</td>\n",
       "      <td>0.542005</td>\n",
       "      <td>0.506231</td>\n",
       "      <td>0.455667</td>\n",
       "      <td>0.278308</td>\n",
       "      <td>0.732210</td>\n",
       "      <td>0.429512</td>\n",
       "      <td>0.266777</td>\n",
       "      <td>0.431441</td>\n",
       "      <td>0.676150</td>\n",
       "      <td>0.549790</td>\n",
       "      <td>0.491202</td>\n",
       "      <td>0.540061</td>\n",
       "      <td>0.388292</td>\n",
       "      <td>0.501946</td>\n",
       "      <td>0.713977</td>\n",
       "      <td>0.600301</td>\n",
       "      <td>0.697637</td>\n",
       "      <td>0.478588</td>\n",
       "      <td>0.323442</td>\n",
       "      <td>0.503482</td>\n",
       "      <td>0.286948</td>\n",
       "      <td>0.147788</td>\n",
       "      <td>0.555267</td>\n",
       "      <td>0.374413</td>\n",
       "      <td>0.234260</td>\n",
       "      <td>0.523616</td>\n",
       "      <td>0.472941</td>\n",
       "      <td>0.321634</td>\n",
       "      <td>0.290066</td>\n",
       "      <td>0.373626</td>\n",
       "      <td>0.162326</td>\n",
       "      <td>0.188749</td>\n",
       "      <td>0.241540</td>\n",
       "      <td>0.072156</td>\n",
       "      <td>0.400401</td>\n",
       "      <td>0.826589</td>\n",
       "      <td>0.795333</td>\n",
       "      <td>0.365662</td>\n",
       "      <td>0.541328</td>\n",
       "      <td>0.311284</td>\n",
       "      <td>0.407825</td>\n",
       "      <td>0.488073</td>\n",
       "      <td>0.293583</td>\n",
       "      <td>0.652288</td>\n",
       "      <td>0.562604</td>\n",
       "      <td>0.424493</td>\n",
       "      <td>0.009669</td>\n",
       "      <td>0.029061</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.174107</td>\n",
       "      <td>0.163321</td>\n",
       "      <td>0.095551</td>\n",
       "      <td>0.752637</td>\n",
       "      <td>0.387832</td>\n",
       "      <td>0.185024</td>\n",
       "      <td>0.348909</td>\n",
       "      <td>0.635720</td>\n",
       "      <td>0.465276</td>\n",
       "      <td>0.597469</td>\n",
       "      <td>0.309881</td>\n",
       "      <td>0.138456</td>\n",
       "      <td>0.435811</td>\n",
       "      <td>0.509114</td>\n",
       "      <td>0.340705</td>\n",
       "      <td>0.672473</td>\n",
       "      <td>0.298856</td>\n",
       "      <td>0.149022</td>\n",
       "      <td>0.478061</td>\n",
       "      <td>0.528161</td>\n",
       "      <td>0.362653</td>\n",
       "      <td>0.632067</td>\n",
       "      <td>0.531175</td>\n",
       "      <td>0.387470</td>\n",
       "      <td>0.407135</td>\n",
       "      <td>0.526068</td>\n",
       "      <td>0.373733</td>\n",
       "      <td>0.643790</td>\n",
       "      <td>0.534757</td>\n",
       "      <td>0.396267</td>\n",
       "      <td>0.362759</td>\n",
       "      <td>0.391483</td>\n",
       "      <td>0.243373</td>\n",
       "      <td>0.681846</td>\n",
       "      <td>0.222939</td>\n",
       "      <td>0.105115</td>\n",
       "      <td>0.524689</td>\n",
       "      <td>0.286852</td>\n",
       "      <td>0.164446</td>\n",
       "      <td>0.781792</td>\n",
       "      <td>0.406446</td>\n",
       "      <td>0.260007</td>\n",
       "      <td>0.616986</td>\n",
       "      <td>0.766661</td>\n",
       "      <td>0.605143</td>\n",
       "      <td>0.416471</td>\n",
       "      <td>0.532536</td>\n",
       "      <td>0.302367</td>\n",
       "      <td>0.585827</td>\n",
       "      <td>0.662927</td>\n",
       "      <td>0.614202</td>\n",
       "      <td>0.645751</td>\n",
       "      <td>0.775026</td>\n",
       "      <td>0.613481</td>\n",
       "      <td>0.686209</td>\n",
       "      <td>0.584828</td>\n",
       "      <td>0.395828</td>\n",
       "      <td>0.315782</td>\n",
       "      <td>0.124489</td>\n",
       "      <td>0.063318</td>\n",
       "      <td>0.215885</td>\n",
       "      <td>0.452068</td>\n",
       "      <td>0.204520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.190306</td>\n",
       "      <td>0.162489</td>\n",
       "      <td>0.094997</td>\n",
       "      <td>0.818058</td>\n",
       "      <td>0.454506</td>\n",
       "      <td>0.242719</td>\n",
       "      <td>0.510609</td>\n",
       "      <td>0.609768</td>\n",
       "      <td>0.434636</td>\n",
       "      <td>0.484726</td>\n",
       "      <td>0.371896</td>\n",
       "      <td>0.184652</td>\n",
       "      <td>0.459279</td>\n",
       "      <td>0.481339</td>\n",
       "      <td>0.313109</td>\n",
       "      <td>0.752121</td>\n",
       "      <td>0.376308</td>\n",
       "      <td>0.208483</td>\n",
       "      <td>0.467799</td>\n",
       "      <td>0.605514</td>\n",
       "      <td>0.446873</td>\n",
       "      <td>0.773822</td>\n",
       "      <td>0.520902</td>\n",
       "      <td>0.376888</td>\n",
       "      <td>0.479969</td>\n",
       "      <td>0.372597</td>\n",
       "      <td>0.229764</td>\n",
       "      <td>0.620313</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.352543</td>\n",
       "      <td>0.513828</td>\n",
       "      <td>0.403445</td>\n",
       "      <td>0.253810</td>\n",
       "      <td>0.848489</td>\n",
       "      <td>0.381108</td>\n",
       "      <td>0.220689</td>\n",
       "      <td>0.612730</td>\n",
       "      <td>0.477182</td>\n",
       "      <td>0.327903</td>\n",
       "      <td>0.772189</td>\n",
       "      <td>0.301585</td>\n",
       "      <td>0.173730</td>\n",
       "      <td>0.390945</td>\n",
       "      <td>0.514024</td>\n",
       "      <td>0.288482</td>\n",
       "      <td>0.241661</td>\n",
       "      <td>0.281830</td>\n",
       "      <td>0.094690</td>\n",
       "      <td>0.414717</td>\n",
       "      <td>0.831555</td>\n",
       "      <td>0.801012</td>\n",
       "      <td>0.463441</td>\n",
       "      <td>0.685964</td>\n",
       "      <td>0.486380</td>\n",
       "      <td>0.523306</td>\n",
       "      <td>0.765962</td>\n",
       "      <td>0.626421</td>\n",
       "      <td>0.320781</td>\n",
       "      <td>0.135522</td>\n",
       "      <td>0.069769</td>\n",
       "      <td>0.061493</td>\n",
       "      <td>0.168321</td>\n",
       "      <td>0.028419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    meanTempogram  stdTempogram  varTempogram  meanMFCC_1  stdMFCC_1  \\\n",
       "1        0.251674      0.209781      0.127566    0.601865   0.411215   \n",
       "4        0.174107      0.163321      0.095551    0.752637   0.387832   \n",
       "13       0.190306      0.162489      0.094997    0.818058   0.454506   \n",
       "\n",
       "    varMFCC_1  meanMFCC_2  stdMFCC_2  varMFCC_2  meanMFCC_3  stdMFCC_3  \\\n",
       "1    0.204393    0.617099   0.448078   0.266062    0.569494   0.381634   \n",
       "4    0.185024    0.348909   0.635720   0.465276    0.597469   0.309881   \n",
       "13   0.242719    0.510609   0.609768   0.434636    0.484726   0.371896   \n",
       "\n",
       "    varMFCC_3  meanMFCC_4  stdMFCC_4  varMFCC_4  meanMFCC_5  stdMFCC_5  \\\n",
       "1    0.192466    0.598732   0.686925   0.542005    0.506231   0.455667   \n",
       "4    0.138456    0.435811   0.509114   0.340705    0.672473   0.298856   \n",
       "13   0.184652    0.459279   0.481339   0.313109    0.752121   0.376308   \n",
       "\n",
       "    varMFCC_5  meanMFCC_6  stdMFCC_6  varMFCC_6  meanMFCC_7  stdMFCC_7  \\\n",
       "1    0.278308    0.732210   0.429512   0.266777    0.431441   0.676150   \n",
       "4    0.149022    0.478061   0.528161   0.362653    0.632067   0.531175   \n",
       "13   0.208483    0.467799   0.605514   0.446873    0.773822   0.520902   \n",
       "\n",
       "    varMFCC_7  meanMFCC_8  stdMFCC_8  varMFCC_8  meanMFCC_9  stdMFCC_9  \\\n",
       "1    0.549790    0.491202   0.540061   0.388292    0.501946   0.713977   \n",
       "4    0.387470    0.407135   0.526068   0.373733    0.643790   0.534757   \n",
       "13   0.376888    0.479969   0.372597   0.229764    0.620313   0.491667   \n",
       "\n",
       "    varMFCC_9  meanMFCC_10  stdMFCC_10  varMFCC_10  meanMFCC_11  stdMFCC_11  \\\n",
       "1    0.600301     0.697637    0.478588    0.323442     0.503482    0.286948   \n",
       "4    0.396267     0.362759    0.391483    0.243373     0.681846    0.222939   \n",
       "13   0.352543     0.513828    0.403445    0.253810     0.848489    0.381108   \n",
       "\n",
       "    varMFCC_11  meanMFCC_12  stdMFCC_12  varMFCC_12  meanMFCC_13  stdMFCC_13  \\\n",
       "1     0.147788     0.555267    0.374413    0.234260     0.523616    0.472941   \n",
       "4     0.105115     0.524689    0.286852    0.164446     0.781792    0.406446   \n",
       "13    0.220689     0.612730    0.477182    0.327903     0.772189    0.301585   \n",
       "\n",
       "    varMFCC_13  meanSpectralCentroid  stdSpectralCentroid  \\\n",
       "1     0.321634              0.290066             0.373626   \n",
       "4     0.260007              0.616986             0.766661   \n",
       "13    0.173730              0.390945             0.514024   \n",
       "\n",
       "    varSpectralCentroid  meanZeroCrossingRate  stdZeroCrossingRate  \\\n",
       "1              0.162326              0.188749             0.241540   \n",
       "4              0.605143              0.416471             0.532536   \n",
       "13             0.288482              0.241661             0.281830   \n",
       "\n",
       "    varZeroCrossingRate  meanChromaFrequencies  stdChromaFrequencies  \\\n",
       "1              0.072156               0.400401              0.826589   \n",
       "4              0.302367               0.585827              0.662927   \n",
       "13             0.094690               0.414717              0.831555   \n",
       "\n",
       "    varChromaFrequencies  meanSpectralRollOff  stdSpectralRollOff  \\\n",
       "1               0.795333             0.365662            0.541328   \n",
       "4               0.614202             0.645751            0.775026   \n",
       "13              0.801012             0.463441            0.685964   \n",
       "\n",
       "    varSpectralRollOff  meanSpectralBandwidth  stdSpectralBandwidth  \\\n",
       "1             0.311284               0.407825              0.488073   \n",
       "4             0.613481               0.686209              0.584828   \n",
       "13            0.486380               0.523306              0.765962   \n",
       "\n",
       "    varSpectralBandwidth  meanSpectralContrast  stdSpectralContrast  \\\n",
       "1               0.293583              0.652288             0.562604   \n",
       "4               0.395828              0.315782             0.124489   \n",
       "13              0.626421              0.320781             0.135522   \n",
       "\n",
       "    varSpectralContrast  meanSpectralFlatness  stdSpectralFlatness  \\\n",
       "1              0.424493              0.009669             0.029061   \n",
       "4              0.063318              0.215885             0.452068   \n",
       "13             0.069769              0.061493             0.168321   \n",
       "\n",
       "    varSpectralFlatness  \n",
       "1              0.000862  \n",
       "4              0.204520  \n",
       "13             0.028419  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(200, 63)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)\n",
    "train.shape\n",
    "\n",
    "test.head(3)\n",
    "test.shape\n",
    "\n",
    "X_test.head(3)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Upload the data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_file = \"train.csv\"\n",
    "train.to_csv(train_file, index=False)\n",
    "train_s3_path = session.upload_data(train_file, key_prefix=\"{}/data\".format(prefix))\n",
    "\n",
    "test_file = \"test.csv\"\n",
    "test.to_csv(test_file, index=False)\n",
    "test_s3_path = session.upload_data(test_file, key_prefix=\"{}/data\".format(prefix))\n",
    "\n",
    "X_test_file = \"X_test.csv\"\n",
    "X_test.to_csv(X_test_file, index=False)\n",
    "X_test_s3_path = session.upload_data(X_test_file, key_prefix=\"{}/data\".format(prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Hyperparameter Selection\n",
    "\n",
    "The minimum required settings for training is just a target label, `init_args['label']`.\n",
    "\n",
    "Additional optional hyperparameters can be passed to the `autogluon.tabular.TabularPredictor.fit` function via `fit_args`.\n",
    "\n",
    "Below shows a more in depth example of AutoGluon-Tabular hyperparameters from the example [Predicting Columns in a Table - In Depth](https://auto.gluon.ai/stable/tutorials/tabular_prediction/tabular-indepth.html). Please see [fit parameters](https://auto.gluon.ai/stable/_modules/autogluon/tabular/predictor/predictor.html#TabularPredictor) for further information. Note that in order for hyperparameter ranges to work in SageMaker, values passed to the `fit_args['hyperparameters']` must be represented as strings.\n",
    "\n",
    "```python\n",
    "nn_options = {\n",
    "    'num_epochs': \"10\",\n",
    "    'learning_rate': \"ag.space.Real(1e-4, 1e-2, default=5e-4, log=True)\",\n",
    "    'activation': \"ag.space.Categorical('relu', 'softrelu', 'tanh')\",\n",
    "    'layers': \"ag.space.Categorical([100],[1000],[200,100],[300,200,100])\",\n",
    "    'dropout_prob': \"ag.space.Real(0.0, 0.5, default=0.1)\"\n",
    "}\n",
    "\n",
    "gbm_options = {\n",
    "    'num_boost_round': \"100\",\n",
    "    'num_leaves': \"ag.space.Int(lower=26, upper=66, default=36)\"\n",
    "}\n",
    "\n",
    "model_hps = {'NN': nn_options, 'GBM': gbm_options} \n",
    "\n",
    "init_args = {\n",
    "  'eval_metric' : 'roc_auc'  \n",
    "  'label': 'y'\n",
    "}\n",
    "\n",
    "fit_args = {\n",
    "  'presets': ['best_quality', 'optimize_for_deployment'],\n",
    "  'time_limits': 60*10,\n",
    "  'hyperparameters': model_hps,\n",
    "  'hyperparameter_tune': True,\n",
    "  'search_strategy': 'skopt'\n",
    "}\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "  'fit_args': fit_args,\n",
    "  'feature_importance': True\n",
    "}\n",
    "```\n",
    "**Note:** Your hyperparameter choices may affect the size of the model package, which could result in additional time taken to upload your model and complete training. Including `'optimize_for_deployment'` in the list of `fit_args['presets']` is recommended to greatly reduce upload times.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Define required label and optional additional parameters\n",
    "init_args = {\"label\": \"genre\"}\n",
    "\n",
    "# Define additional parameters\n",
    "fit_args = {\n",
    "    # Adding 'best_quality' to presets list will result in better performance (but longer runtime)\n",
    "    \"presets\": [\"best_quality\"],  \n",
    "    \"time_limit\": 60*60,\n",
    "\n",
    "}\n",
    "\n",
    "# Pass fit_args to SageMaker estimator hyperparameters # \"feature_importance\": True\n",
    "hyperparameters = {\"init_args\": init_args, \"fit_args\": fit_args}\n",
    "\n",
    "tags = [{\"Key\": \"AlgorithmName\", \"Value\": \"AutoGluon-Tabular\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Train\n",
    "\n",
    "For local training set `train_instance_type` to `local` .   \n",
    "For non-local training the recommended instance type is `ml.m5.2xlarge`.   \n",
    "\n",
    "**Note:** Depending on how many underlying models are trained, `train_volume_size` may need to be increased so that they all fit on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 32ym1asrgc-algo-1-82cy1 ... \n",
      "Creating 32ym1asrgc-algo-1-82cy1 ... done\n",
      "Attaching to 32ym1asrgc-algo-1-82cy1\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,278 sagemaker-training-toolkit INFO     Imported framework sagemaker_mxnet_container.training\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,281 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,281 sagemaker-training-toolkit INFO     Failed to parse hyperparameter init_args value {'label': 'genre'} to Json.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Returning the value itself\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,281 sagemaker-training-toolkit INFO     Failed to parse hyperparameter fit_args value {'presets': ['best_quality'], 'time_limit': 3600} to Json.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Returning the value itself\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,293 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1-82cy1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"fit_args\":\"{\\'presets\\': [\\'best_quality\\'], \\'time_limit\\': 3600}\",\"init_args\":\"{\\'label\\': \\'genre\\'}\"}', 'SM_USER_ENTRY_POINT': 'train.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-82cy1\",\"hosts\":[\"algo-1-82cy1\"]}', 'SM_INPUT_DATA_CONFIG': '{\"testing\":{\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"testing\",\"training\"]', 'SM_CURRENT_HOST': 'algo-1-82cy1', 'SM_MODULE_NAME': 'train', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '8', 'SM_NUM_GPUS': '0', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': '/opt/ml/code', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-82cy1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1-82cy1\"],\"hyperparameters\":{\"fit_args\":\"{\\'presets\\': [\\'best_quality\\'], \\'time_limit\\': 3600}\",\"init_args\":\"{\\'label\\': \\'genre\\'}\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"autogluon-sagemaker-training-2021-12-01-19-58-00-002\",\"log_level\":20,\"master_hostname\":\"algo-1-82cy1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-82cy1\",\"hosts\":[\"algo-1-82cy1\"]},\"user_entry_point\":\"train.py\"}', 'SM_USER_ARGS': '[\"--fit_args\",\"{\\'presets\\': [\\'best_quality\\'], \\'time_limit\\': 3600}\",\"--init_args\",\"{\\'label\\': \\'genre\\'}\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_CHANNEL_TESTING': '/opt/ml/input/data/testing', 'SM_HP_INIT_ARGS': \"{'label': 'genre'}\", 'SM_HP_FIT_ARGS': \"{'presets': ['best_quality'], 'time_limit': 3600}\"}\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,295 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,295 sagemaker-training-toolkit INFO     Failed to parse hyperparameter init_args value {'label': 'genre'} to Json.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Returning the value itself\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,295 sagemaker-training-toolkit INFO     Failed to parse hyperparameter fit_args value {'presets': ['best_quality'], 'time_limit': 3600} to Json.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Returning the value itself\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,310 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,311 sagemaker-training-toolkit INFO     Failed to parse hyperparameter init_args value {'label': 'genre'} to Json.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Returning the value itself\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,311 sagemaker-training-toolkit INFO     Failed to parse hyperparameter fit_args value {'presets': ['best_quality'], 'time_limit': 3600} to Json.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Returning the value itself\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,324 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,324 sagemaker-training-toolkit INFO     Failed to parse hyperparameter init_args value {'label': 'genre'} to Json.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Returning the value itself\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,324 sagemaker-training-toolkit INFO     Failed to parse hyperparameter fit_args value {'presets': ['best_quality'], 'time_limit': 3600} to Json.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Returning the value itself\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 2021-12-01 20:00:31,335 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m \n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Training Env:\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m \n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m {\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m         \"training\": \"/opt/ml/input/data/training\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m         \"testing\": \"/opt/ml/input/data/testing\"\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     },\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"current_host\": \"algo-1-82cy1\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m         \"algo-1-82cy1\"\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     ],\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m         \"init_args\": \"{'label': 'genre'}\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m         \"fit_args\": \"{'presets': ['best_quality'], 'time_limit': 3600}\"\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     },\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m         \"training\": {\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m         },\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m         \"testing\": {\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m         }\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     },\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"job_name\": \"autogluon-sagemaker-training-2021-12-01-19-58-00-002\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"master_hostname\": \"algo-1-82cy1\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m         \"current_host\": \"algo-1-82cy1\",\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m             \"algo-1-82cy1\"\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m         ]\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     },\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m }\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m \n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Environment variables:\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m \n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_HOSTS=[\"algo-1-82cy1\"]\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_HPS={\"fit_args\":\"{'presets': ['best_quality'], 'time_limit': 3600}\",\"init_args\":\"{'label': 'genre'}\"}\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-82cy1\",\"hosts\":[\"algo-1-82cy1\"]}\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_INPUT_DATA_CONFIG={\"testing\":{\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_CHANNELS=[\"testing\",\"training\"]\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_CURRENT_HOST=algo-1-82cy1\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-82cy1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1-82cy1\"],\"hyperparameters\":{\"fit_args\":\"{'presets': ['best_quality'], 'time_limit': 3600}\",\"init_args\":\"{'label': 'genre'}\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"autogluon-sagemaker-training-2021-12-01-19-58-00-002\",\"log_level\":20,\"master_hostname\":\"algo-1-82cy1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-82cy1\",\"hosts\":[\"algo-1-82cy1\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_USER_ARGS=[\"--fit_args\",\"{'presets': ['best_quality'], 'time_limit': 3600}\",\"--init_args\",\"{'label': 'genre'}\"]\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_CHANNEL_TESTING=/opt/ml/input/data/testing\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_HP_INIT_ARGS={'label': 'genre'}\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m SM_HP_FIT_ARGS={'presets': ['best_quality'], 'time_limit': 3600}\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m \n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m \n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m /usr/local/bin/python3.6 train.py --fit_args {'presets': ['best_quality'], 'time_limit': 3600} --init_args {'label': 'genre'}\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m \n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m \n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m /opt/ml/input:\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m total 0\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m drwxrwxr-x 2 1000 1000 89 Dec  1 19:58 config\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m drwx------ 4 1000 1000 37 Dec  1 19:58 data\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m \n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m /opt/ml/input/config:\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m total 12\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m -rw-rw-r-- 1 1000 1000 100 Dec  1 19:58 hyperparameters.json\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m -rw-rw-r-- 1 1000 1000  85 Dec  1 19:58 inputdataconfig.json\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m -rw-rw-r-- 1 1000 1000  59 Dec  1 19:58 resourceconfig.json\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m \n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m /opt/ml/input/data:\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m total 0\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m drwx------ 2 1000 1000 22 Dec  1 19:58 testing\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m drwx------ 2 1000 1000 23 Dec  1 19:58 training\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m \n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m /opt/ml/input/data/testing:\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m total 244\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m -rw-rw-r-- 1 1000 1000 246454 Dec  1 19:58 test.csv\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m \n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m /opt/ml/input/data/training:\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m total 960\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m -rw-rw-r-- 1 1000 1000 981554 Dec  1 19:58 train.csv\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:root:0\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m IPython could not be loaded!\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m DEBUG:asyncio:Using selector: EpollSelector\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m fit_args:\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m presets,  type: <class 'list'>,  value: ['best_quality']\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m time_limit,  type: <class 'int'>,  value: 3600\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Train files: ['train.csv']\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m WARNING:autogluon.core.utils.utils:Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/opt/ml/model\"\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:root:Presets specified: ['best_quality']\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.learner.default_learner:Beginning AutoGluon training ... Time limit = 3600s\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.learner.default_learner:AutoGluon will save models to \"/opt/ml/model/\"\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.learner.default_learner:AutoGluon Version:  0.1.0\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.learner.default_learner:Train Data Rows:    800\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.learner.default_learner:Train Data Columns: 63\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.learner.default_learner:Preprocessing data ...\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Level 25:autogluon.core.utils.utils:AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.core.utils.utils:\t10 unique label values:  ['jazz', 'metal', 'country', 'classical', 'blues', 'hiphop', 'reggae', 'disco', 'pop', 'rock']\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Level 25:autogluon.core.utils.utils:\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.learner.default_learner:Train Data Class Count: 10\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.learner.default_learner:Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\tAvailable Memory:                    31234.69 MB\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\tTrain Data (Original)  Memory Usage: 0.4 MB (0.0% of available memory)\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\tStage 1 Generators:\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\tStage 2 Generators:\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\tStage 3 Generators:\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\tStage 4 Generators:\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.core.features.feature_metadata:\t\t('float', []) : 63 | ['meanTempogram', 'stdTempogram', 'varTempogram', 'meanMFCC_1', 'stdMFCC_1', ...]\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.core.features.feature_metadata:\t\t('float', []) : 63 | ['meanTempogram', 'stdTempogram', 'varTempogram', 'meanMFCC_1', 'stdMFCC_1', ...]\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\t0.1s = Fit runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\t63 features in original data used to generate 63 features in processed data.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.features.generators.abstract:\tTrain Data (Processed) Memory Usage: 0.4 MB (0.0% of available memory)\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.learner.default_learner:Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m Level 25:autogluon.tabular.trainer.abstract_trainer:AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\tTo change this, specify the eval_metric argument of fit()\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 1799.96s of the 3599.91s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.7825\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t28.23s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.23s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1771.45s of the 3571.4s of remaining time.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.7638\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t45.38s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t1.09s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1724.94s of the 3524.89s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6338\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.03s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.85s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1724.04s of the 3523.99s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.655\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.04s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.85s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1723.13s of the 3523.09s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6838\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t6.79s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.82s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1715.28s of the 3515.23s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.675\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t8.37s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.82s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1705.85s of the 3505.8s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.68\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t5.98s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.82s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1698.6s of the 3498.55s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6762\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t5.98s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.82s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: LightGBM_BAG_L1 ... Training model for up to 1691.35s of the 3491.31s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.7238\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t22.84s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.05s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1667.86s of the 3467.81s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.7375\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t16.02s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.05s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: CatBoost_BAG_L1 ... Training model for up to 1651.18s of the 3451.13s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.695\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t84.72s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.02s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: XGBoost_BAG_L1 ... Training model for up to 1566.4s of the 3366.35s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.7025\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t35.03s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.05s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1530.29s of the 3330.25s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6738\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t75.22s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.03s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Repeating k-fold bagging: 2/20\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 1454.28s of the 3254.24s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.7675\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t55.58s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.44s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1426.66s of the 3226.61s of remaining time.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.7675\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t109.99s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t2.33s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1360.76s of the 3160.71s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6438\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.07s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t1.69s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1359.87s of the 3159.82s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6538\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.07s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t1.69s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1358.97s of the 3158.93s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6788\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t13.56s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t1.64s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1351.17s of the 3151.12s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.67\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t16.74s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t1.64s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1341.8s of the 3141.75s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6962\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t11.96s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t1.64s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1334.53s of the 3134.48s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6825\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t11.95s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t1.64s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: LightGBM_BAG_L1 ... Training model for up to 1327.26s of the 3127.22s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.7163\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t44.84s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.08s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1304.75s of the 3104.7s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.725\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t33.14s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.09s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: CatBoost_BAG_L1 ... Training model for up to 1287.03s of the 3086.98s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6975\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t184.28s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.04s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: XGBoost_BAG_L1 ... Training model for up to 1187.41s of the 2987.36s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.7062\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t71.25s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.1s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1149.83s of the 2949.79s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6975\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t155.81s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.08s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Repeating k-fold bagging: 3/20\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 1067.4s of the 2867.36s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.7638\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t80.7s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.66s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1042.0s of the 2841.95s of remaining time.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.77\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t176.96s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t3.63s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 973.68s of the 2773.64s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6388\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.1s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t2.53s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 972.79s of the 2772.74s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6538\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.1s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t2.53s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 971.89s of the 2771.84s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.685\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t20.33s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t2.46s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 964.1s of the 2764.05s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6762\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t25.11s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t2.46s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 954.71s of the 2754.67s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6925\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t17.93s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t2.46s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 947.45s of the 2747.4s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6812\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t17.92s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t2.46s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: LightGBM_BAG_L1 ... Training model for up to 940.17s of the 2740.12s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.71\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t66.21s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.12s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 918.35s of the 2718.3s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.7275\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t50.01s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.13s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: CatBoost_BAG_L1 ... Training model for up to 900.88s of the 2700.83s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.6988\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t269.0s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.06s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: XGBoost_BAG_L1 ... Training model for up to 816.09s of the 2616.05s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.7125\t = Validation accuracy score\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t109.66s\t = Training runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:\t0.15s\t = Validation runtime\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 776.33s of the 2576.28s of remaining time.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m32ym1asrgc-algo-1-82cy1 |\u001b[0m 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#instance_type = \"ml.m5.2xlarge\"\n",
    "instance_type = 'local'\n",
    "\n",
    "ecr_image = f\"{ecr_uri_prefix}/{training_algorithm_name}:latest\"\n",
    "\n",
    "estimator = Estimator(\n",
    "    image_uri=ecr_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    hyperparameters=hyperparameters,\n",
    "    volume_size=1000,\n",
    "    tags=tags,\n",
    ")\n",
    "\n",
    "# Set inputs. Test data is optional, but requires a label column.\n",
    "inputs = {\"training\": train_s3_path, \"testing\": test_s3_path}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the performance of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ag_utils import launch_viewer\n",
    "\n",
    "launch_viewer(is_debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Create predictor object\n",
    "class AutoGluonTabularPredictor(Predictor):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            *args, serializer=CSVSerializer(), deserializer=StringDeserializer(), **kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ecr_image = f\"{ecr_uri_prefix}/{inference_algorithm_name}:latest\"\n",
    "\n",
    "if instance_type == \"local\":\n",
    "    model = estimator.create_model(image_uri=ecr_image, role=role)\n",
    "else:\n",
    "    # model_uri = os.path.join(estimator.output_path, estimator._current_job_name, \"output\", \"model.tar.gz\")\n",
    "    model_uri = estimator.model_data\n",
    "    model = Model(\n",
    "        ecr_image,\n",
    "        model_data=model_uri,\n",
    "        role=role,\n",
    "        sagemaker_session=session,\n",
    "        predictor_cls=AutoGluonTabularPredictor,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Batch Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "For local mode, either `s3://<bucket>/<prefix>/output/` or `file:///<absolute_local_path>` can be used as outputs.\n",
    "\n",
    "By including the label column in the test data, you can also evaluate prediction performance (In this case, passing `test_s3_path` instead of `X_test_s3_path`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_path = f\"s3://{bucket}/{prefix}/output/\"\n",
    "# output_path = f'file://{os.getcwd()}'\n",
    "\n",
    "transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    strategy=\"MultiRecord\",\n",
    "    max_payload=6,\n",
    "    max_concurrent_transforms=1,\n",
    "    output_path=output_path,\n",
    ")\n",
    "\n",
    "transformer.transform(test_s3_path, content_type=\"text/csv\", split_type=\"Line\")\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Deploy remote or local endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.2xlarge\"\n",
    "# instance_type = 'local'\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Attach to endpoint (or reattach if kernel was restarted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Select standard or local session based on instance_type\n",
    "if instance_type == \"local\":\n",
    "    sess = local_session\n",
    "else:\n",
    "    sess = session\n",
    "\n",
    "# Attach to endpoint\n",
    "predictor = AutoGluonTabularPredictor(predictor.endpoint_name, sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Predict on unlabeled test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(predictor.endpoint_name)\n",
    "\n",
    "!aws sagemaker list-endpoints --region us-east-1\n",
    "\n",
    "results = predictor.predict(X_test.to_csv(index=False)).splitlines()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['jazz', 'metal', 'country', 'classical', 'blues', 'hiphop', 'reggae', 'disco', 'pop', 'rock']\n",
    "\n",
    "#split the result string\n",
    "prob_results = [result.split(\",\") for result in results ]\n",
    "\n",
    "#cast each item from a string to a float for probability\n",
    "for i in range(len(prob_results)):\n",
    "    predicton = prob_results[i]\n",
    "    for k in  range(len(predicton)):\n",
    "        prob_results[i][k] = float(prob_results[i][k])\n",
    "\n",
    "#print(prob_results)\n",
    "for result in prob_results:\n",
    "    print(result)\n",
    "    max_index = result.index(max(result))\n",
    "    print(max_index)\n",
    "    print(genres[max_index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Predict on data that includes label column  \n",
    "Prediction performance metrics will be printed to endpoint logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "results = predictor.predict(test.to_csv(index=False)).splitlines()\n",
    "\n",
    "# Check output\n",
    "threshold = 0.5\n",
    "y_results = np.array([\"yes\" if float(i.split(\",\")[1]) > threshold else \"no\" for i in results])\n",
    "\n",
    "print(Counter(y_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Check that classification performance metrics match evaluation printed to endpoint logs as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "y_results = np.array([\"yes\" if float(i.split(\",\")[1]) > threshold else \"no\" for i in results])\n",
    "\n",
    "print(\"accuracy: {}\".format(accuracy_score(y_true=y_test, y_pred=y_results)))\n",
    "print(classification_report(y_true=y_test, y_pred=y_results, digits=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Clean up endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability with Amazon SageMaker Clarify\n",
    "\n",
    "There are growing business needs and legislative regulations that require explainations of why a model made a certain decision. SHAP (SHapley Additive exPlanations) is an approach to explain the output of machine learning models. SHAP values represent a feature's contribution to a change in the model output. SageMaker Clarify uses SHAP to explain the contribution that each input feature makes to the final decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set parameters for SHAP calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "num_rows = 500\n",
    "\n",
    "# Write a csv file used by SageMaker Clarify\n",
    "test_explainavility_file = \"test_explainavility.csv\"\n",
    "train.head(num_rows).to_csv(test_explainavility_file, index=False, header=False)\n",
    "test_explainavility_s3_path = session.upload_data(\n",
    "    test_explainavility_file, key_prefix=\"{}/data\".format(prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify computing resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import clarify\n",
    "\n",
    "model_name = estimator.latest_training_job.job_name\n",
    "container_def = model.prepare_container_def()\n",
    "session.create_model(model_name, role, container_def)\n",
    "\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(\n",
    "    role=role, instance_count=1, instance_type=\"ml.c4.xlarge\", sagemaker_session=session\n",
    ")\n",
    "model_config = clarify.ModelConfig(\n",
    "    model_name=model_name, instance_type=\"ml.c5.xlarge\", instance_count=1, accept_type=\"text/csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run a SageMaker Clarify job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_config = clarify.SHAPConfig(\n",
    "    baseline=X_test.sample(15, random_state=seed).values.tolist(),\n",
    "    num_samples=100,\n",
    "    agg_method=\"mean_abs\",\n",
    ")\n",
    "\n",
    "explainability_output_path = \"s3://{}/{}/{}/clarify-explainability\".format(\n",
    "    bucket, prefix, model_name\n",
    ")\n",
    "explainability_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=test_explainavility_s3_path,\n",
    "    s3_output_path=explainability_output_path,\n",
    "    label=\"y\",\n",
    "    headers=train.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "predictions_config = clarify.ModelPredictedLabelConfig(probability_threshold=0.5)\n",
    "\n",
    "clarify_processor.run_explainability(\n",
    "    data_config=explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### View the Explainability Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the explainability report in Studio under the experiments tab. If you're not a Studio user yet, as with the Bias Report, you can access this report at the following S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(f\"aws s3 cp {explainability_output_path} . --recursive\", shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global explanatory methods allow understanding the model and its feature contributions in aggregate over multiple datapoints. Here we show an aggregate bar plot that plots the mean absolute SHAP value for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(f\"{sys.executable} -m pip install shap\", shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute global shap values out of out.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_ = pd.read_csv(\"explanations_shap/out.csv\")\n",
    "shap_values_.abs().mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(train.head(num_rows).drop([\"y\"], axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap_values = [shap_values_.to_numpy()[:, :num_features], shap_values_.to_numpy()[:, num_features:]]\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    plot_type=\"bar\",\n",
    "    feature_names=train.head(num_rows).drop([\"y\"], axis=1).columns.tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detailed summary plot below can provide more context over the above bar chart. It tells which features are most important and, in addition, their range of effects over the dataset. The color allows us to match how changes in the value of a feature effect the change in prediction. The 'red' indicates higher value of the feature and 'blue' indicates lower (normalized over the features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values_[shap_values_.columns[20:]].to_numpy(), train.head(num_rows).drop([\"y\"], axis=1)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
